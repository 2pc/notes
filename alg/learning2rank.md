

[Learning to Rank using Gradient Descent](https://zhuanlan.zhihu.com/p/20711017) 

[交叉熵代价函数(损失函数)及其求导推导](http://blog.csdn.net/jasonzzj/article/details/52017438)

>
. logistic回归（是非问题）中，y(i)取0或者1； 
. softmax回归（多分类问题）中，y(i)取1,2…k中的一个表示类别标号的一个数（假设共有k类）。

[再理解RankNet算法](http://blog.csdn.net/puqutogether/article/details/43667375)
